---
title: "[XNLI 2.0: Improving XNLI dataset and performance on Cross Lingual Understanding (XLU)](https://docs.google.com/presentation/d/1oY9wpy2gZFSW6UEeXxf4kGOosM5GmdGD/edit?usp=drive_link&ouid=117165800288664224856&rtpof=true&sd=true)"
collection: talks
type: "Recorded Presentation"
permalink: /talks/2012-03-01-talk-1
venue: "Online"
date: 2023-04-07
location: "Mumbai, India"
---

Using cross-lingual understanding and Natural Language Inference, it is possible to train models whose applications extend beyond the training language. We can leverage the power of machine translation to skip the tiresome part of translating datasets from one language to another. In this work, we focus on improving the original XNLI dataset by re-translating the MNLI dataset in all of the 14 different languages present in XNLI, including the test and dev sets of XNLI using Google Translate. We also perform experiments by training models in all 15 languages and analyzing their performance on the task of natural language inference. We then expand our boundary to investigate if we could improve performance in low-resource languages such as Swahili and Urdu by training models in languages other than English.